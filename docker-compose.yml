version: '3'

services:
  spark-master:
    image: sparkhadoopfinal
    ports:
      - "8888:8888"  # Jupyter Notebook
      - "4040:4040"  # Spark Web UI
    volumes:
      - /Users/luca/Desktop/Università/BDA/Big_Data_Analytics/:/opt/spark/work-dir/data
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_HOME=/opt/spark
    command: /bin/bash -c "source /opt/spark/sbin/start-master.sh && tail -f /opt/spark/logs/*"
    stdin_open: true

  spark-worker-1:
    image: sparkhadoopfinal
    depends_on:
      - spark-master
    volumes:
      - /Users/luca/Desktop/Università/BDA/Big_Data_Analytics/:/opt/spark/work-dir/data
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    command: /bin/bash -c "source /opt/spark/sbin/start-slave.sh spark://spark-master:7077 && tail -f /opt/spark/logs/*"

  spark-worker-2:
    image: sparkhadoopfinal
    depends_on:
      - spark-master
    volumes:
      - /Users/luca/Desktop/Università/BDA/Big_Data_Analytics/:/opt/spark/work-dir/data
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    command: /bin/bash -c "source /opt/spark/sbin/start-slave.sh spark://spark-master:7077 && tail -f /opt/spark/logs/*"
